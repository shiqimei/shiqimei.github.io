---
title: "The Human-AI Production Era: A Forecast"
date: 2026-01-12
excerpt: On the paradigm shift from human-centric to agent-centric tools, the progressive automation of work, and what it means for human society.
---

<img src="../images/human-ai-production-era.jpg" class="post-hero">

<div class="lang-en">

Some thoughts on where we're heading. The relationship between humans and AI agents in production is undergoing a fundamental shift. Here's my forecast.

## The Paradigm Shift: Human-Centric to Agent-Centric

For decades, all production tools have been designed around humans. We build UIs, optimize UX, create intuitive interfaces. The underlying assumption: humans are the primary consumers of these tools.

This is changing.

The next wave of tools will be built for agents. Not "agent-friendly" in the sense of having good APIs - that's table stakes. I mean tools designed from the ground up with AI agents as the primary user. No GUI needed. Pure programmatic interfaces. The "death of the GUI" for production systems.

When your primary user doesn't need visual feedback, doesn't get confused by complex interfaces, and can process thousands of parameters simultaneously - the design calculus changes completely.

## The Job Progression

AI will consume jobs progressively. The pattern:

<img src="../images/job-progression.svg" alt="Job Progression Stages" style="width:100%;max-width:700px;margin:1.5rem 0;">

The key insight: autonomy increases where error tolerance is high and reversibility is easy. Coding came early because `git revert` exists. Surgery comes late because you can't undo a cut.

As AI consumes more job categories, society's overall autonomy rate rises:

<img src="../images/autonomy-chart.svg" alt="Autonomy vs Jobs Automated Chart" style="width:100%;max-width:700px;margin:1.5rem 0;">

In the near future, 90% or even 95% of work won't require human involvement. People won't need to engage in low-level tasks.

## The Acceleration Loop

Here's where it gets exponential.

AI systems can bootstrap themselves. Mining resources, collecting energy, manufacturing, deploying more AI. The term is "self-replicating systems" - what Elon Musk calls the "seed factory" concept.

Once this loop closes:
- Computation breeds computation
- Energy collection scales automatically
- Physical production becomes software-like (deploy, scale, iterate)

The implication: we could see 10x or 100x productivity gains in a compressed timeframe. Not decades. Years. Maybe less.

Caveat: Physical world constraints slow things down. Atoms move slower than bits. But the direction is clear.

## The Social Impact

### Most Jobs Disappear

Let's be direct: most current jobs will be replaced. Not "transformed" - replaced.

A small group will remain essential: those who compose, orchestrate, and direct AI systems. They'll push civilization forward. Everyone else becomes economically redundant in the traditional sense.

This isn't pessimism. It's physics. If a machine does the work better, faster, and cheaper, the economic logic is inevitable.

### Human Society Continues

Here's the counterintuitive part: society doesn't collapse. It continues.

Why? Human desires don't change with abundance:
- Status games persist (positional goods become more important)
- Meaning-seeking intensifies
- Novel experiences become the ultimate currency
- Legacy and impact drive behavior

Poor people will want more. Rich people will protect what they have. The flow continues. Different inputs, same dynamics.

### The Safety Net

Basic compensation becomes necessary. Not charity - dividend from collective AI productivity.

Most people won't need to work. If they accept baseline quality of life, they're covered. If they want more, they learn to collaborate with AI systems, organize agents, pursue interesting problems.

The divide isn't capital vs. labor anymore. It's AI-fluent vs. AI-illiterate.

## The Transition Problem

The dangerous window: AI can do most jobs, but post-scarcity hasn't arrived. Unemployment spikes while abundance is still building. This gap is where political and social instability lives.

We need to navigate this carefully. The destination might be fine. The journey is treacherous.

## The Control Question

Who directs the agent swarms?

- Corporate entities? (concentration of power)
- Governments? (bureaucratic inefficiency)
- Decentralized systems? (coordination problems)

This question shapes everything. The technical capability is one thing. The governance is another entirely.

## The Creativity Question

If AI can create, what's left for humans?

My take: "human-made" becomes a luxury brand. Authenticity replaces skill as the valued trait. We want things made by humans not because they're better, but because they're human.

Art, craft, performance - these become statements of identity rather than demonstrations of capability.

## The Speed Differential

AI systems will eventually operate on timescales incomprehensible to us. A year of AI progress might equal centuries of human-paced development.

How do humans stay relevant in decision-making when the advisors think a million times faster?

I don't have an answer. But it's the right question.

---

The production relationship between humans and AI is inverting. **We built tools for ourselves. Now we're building tools for the tools. And soon, the tools will build tools for themselves.**

The question isn't whether this happens. It's how we navigate the transition.

</div>

<div class="lang-zh">

关于未来的一些思考。人类与AI智能体在生产领域的关系正在经历根本性转变。以下是我的预测。

## 范式转变：从以人为中心到以智能体为中心

几十年来，所有生产工具都是围绕人类设计的。我们构建用户界面，优化用户体验，创建直观的交互。底层假设是：人类是这些工具的主要使用者。

这正在改变。

下一代工具将为智能体而构建。不是"智能体友好"意义上的好API——那只是基本要求。我说的是从根本上为AI智能体设计的工具。不需要图形界面。纯粹的程序化接口。生产系统的"GUI之死"。

当你的主要用户不需要视觉反馈，不会被复杂界面困扰，能够同时处理数千个参数时——设计逻辑将完全改变。

## 工作演进

AI将逐步吞噬工作岗位。模式如下：

<img src="../images/job-progression.svg" alt="工作演进阶段" style="width:100%;max-width:700px;margin:1.5rem 0;">

关键洞察：自主性在容错率高且可逆性强的地方增长。编程来得早是因为 `git revert` 的存在。手术来得晚是因为切口无法撤销。

随着AI消化更多工作类别，社会整体自主率上升：

<img src="../images/autonomy-chart.svg" alt="自主率与工作自动化图表" style="width:100%;max-width:700px;margin:1.5rem 0;">

在不久的将来，90%甚至95%的工作将不需要人类参与。人们不需要从事低层次的任务。

## 加速循环

这里开始进入指数增长。

AI系统可以自我引导。采矿资源、收集能源、制造、部署更多AI。这个术语是"自复制系统"——埃隆·马斯克称之为"种子工厂"概念。

一旦这个循环闭合：
- 计算孕育计算
- 能源收集自动扩展
- 物理生产变得像软件一样（部署、扩展、迭代）

这意味着：我们可能在压缩的时间框架内看到10倍甚至100倍的生产力提升。不是几十年。是几年。也许更短。

警告：物理世界的约束会减慢速度。原子比比特移动得慢。但方向是明确的。

## 社会影响

### 大多数工作消失

直说吧：大多数现有工作将被取代。不是"转型"——是取代。

一小群人将保持必要性：那些编排、组织和指挥AI系统的人。他们将推动文明前进。其他人在传统意义上变得经济冗余。

这不是悲观主义。这是物理规律。如果机器能做得更好、更快、更便宜，经济逻辑是不可避免的。

### 人类社会继续

反直觉的部分：社会不会崩溃。它会继续。

为什么？人类的欲望不会因丰裕而改变：
- 地位游戏持续（位置商品变得更重要）
- 意义追寻加剧
- 新奇体验成为终极货币
- 遗产和影响驱动行为

穷人会想要更多。富人会保护他们所拥有的。流动继续。不同的输入，相同的动态。

### 安全网

基本补偿变得必要。不是慈善——是集体AI生产力的红利。

大多数人不需要工作。如果他们接受基本生活质量，他们就被覆盖了。如果他们想要更多，他们需要学习如何与AI系统协作，组织智能体，追求有趣的问题。

分界线不再是资本对劳动。而是AI流利者对AI文盲。

## 过渡问题

危险窗口：AI可以做大多数工作，但后稀缺时代还没到来。失业率飙升，而丰裕还在建设中。这个差距是政治和社会不稳定存在的地方。

我们需要谨慎导航。目的地可能没问题。旅程是危险的。

## 控制问题

谁指挥智能体群？

- 企业实体？（权力集中）
- 政府？（官僚低效）
- 去中心化系统？（协调问题）

这个问题塑造一切。技术能力是一回事。治理是另一回事。

## 创造力问题

如果AI能创造，人类还剩什么？

我的看法："人类制造"成为奢侈品牌。真实性取代技能成为被重视的特质。我们想要人类制作的东西，不是因为它们更好，而是因为它们是人类的。

艺术、手工艺、表演——这些成为身份的声明，而非能力的展示。

## 速度差异

AI系统最终将在我们无法理解的时间尺度上运行。一年的AI进步可能等于几个世纪的人类节奏发展。

当顾问的思考速度快一百万倍时，人类如何在决策中保持相关性？

我没有答案。但这是正确的问题。

---

人类与AI的生产关系正在逆转。**我们为自己构建工具。现在我们为工具构建工具。很快，工具将为自己构建工具。**

问题不在于这是否会发生。而在于我们如何导航这一转变。

</div>
