<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Claude Code for Consulting & Data Analysis: Treating Large Datasets as Codebases - Shiqi Mei</title>
  <link rel="icon" type="image/png" href="../avatar.png">
  <link rel="stylesheet" href="../css/style.css">
</head>
<body>
  <div class="container">
    <a href="/" class="back-link">&larr; back</a>

    <article>
      <header class="post-header">
        <div class="post-header-row">
          <h1 class="post-title">Claude Code for Consulting & Data Analysis: Treating Large Datasets as Codebases</h1>
          <div class="lang-toggle" id="langToggle">
            <button data-lang="en" class="active">EN</button>
            <button data-lang="zh">CN</button>
          </div>
        </div>
        <p class="post-meta">Jan 18, 2026</p>
      </header>

      <div class="post-content">
        <img src="../images/claude-code-data-analysis-pipeline.svg" class="post-hero">

<div class="lang-en">

<p>Working with large datasets (100K-1M records) for consulting is hard. You need to extract top themes, deduplicate content, categorize by business relevance, and generate reports without hallucinations.</p>
<p>This post documents our approach using Claude Code for a real enterprise project: generating biweekly media monitoring reports from 25,000+ news articles.</p>
<p>Three approaches exist. Two don&#39;t work. One does.</p>
<h2>Approach 1: Embeddings + Clustering</h2>
<p>The traditional ML approach:</p>
<ol>
<li>Generate semantic embeddings (Qwen3-Embedding-0.6B)</li>
<li>Run density-based clustering (HDBSCAN)</li>
<li>Recursively sub-cluster until manageable sizes</li>
<li>Use small models for cluster summaries</li>
</ol>
<p><strong>Why it fails:</strong> News data is sparse, not dense. HDBSCAN works when data naturally forms clusters. News articles cover diverse topics with weak semantic connections.</p>
<p>Results:</p>
<ul>
<li>50%+ articles remain unclustered</li>
<li>Aggressive parameters create too many micro-clusters</li>
<li>Even optimized, 30%+ records can&#39;t be classified</li>
</ul>
<p>When data is sparse, clustering doesn&#39;t work.</p>
<h2>Approach 2: Large Context LLMs</h2>
<p>Modern LLMs have massive context windows:</p>
<ul>
<li>Claude Opus 4.5: 200K tokens</li>
<li>Gemini 3 Pro: 1M tokens</li>
</ul>
<p>Strategies to fit large datasets:</p>
<ul>
<li><strong>Sampling</strong>: Take 10% of data to fit within context</li>
<li><strong>Chunking</strong>: Split into multiple sub-datasets, process separately</li>
</ul>
<p><strong>Why it fails:</strong> Hallucination compounds with context length.</p>
<p>As token consumption grows, model attention to facts weakens. Errors accumulate: dates shift, numbers drift, sources get confused, fabricated details appear.</p>
<p>Large context is necessary but insufficient. You need verification mechanisms.</p>
<h2>Approach 3: Treat It as Codebase File Editing</h2>
<p>This is the key insight: <strong>coding agents like Claude Code are optimized for file operations.</strong></p>
<p>Claude Code has:</p>
<ul>
<li><code>Read</code> tool optimized for files up to 2000 lines</li>
<li><code>Edit</code> tool for surgical changes</li>
<li><code>Write</code> tool for file creation</li>
<li><code>Bash</code> for unix commands</li>
</ul>
<p>The reframe: convert your dataset problem into a codebase problem.</p>
<h3>The Conversion</h3>
<ol>
<li><strong>Dump data to CSV</strong>: Export from Excel/JSON to row-based CSV</li>
<li><strong>Preprocess</strong>: Remove whitespace, normalize to compact format</li>
<li><strong>Chunk</strong>: Split into files of ~200 records each (fits in 2000 lines)</li>
<li><strong>Treat as code</strong>: Working with CSV files = working with source code</li>
</ol>
<p>A 200K record dataset becomes ~1000 CSV files. Normal codebase size. Claude Code handles this naturally.</p>
<h3>Labeling at Scale</h3>
</div>

<div class="lang-zh">

<p>处理大规模数据集（10万-100万条记录）做咨询很难。你需要提取顶级主题、去重内容、按业务相关性分类，并生成无幻觉的报告。</p>
<p>本文记录了我们使用 Claude Code 完成一个真实企业项目的方法：从2.5万多篇新闻文章生成双周舆情监测报告。</p>
<p>三种方法。两种不行。一种有效。</p>
<h2>方法一：嵌入向量 + 聚类</h2>
<p>传统机器学习方法：</p>
<ol>
<li>生成语义嵌入向量（Qwen3-Embedding-0.6B）</li>
<li>运行基于密度的聚类（HDBSCAN）</li>
<li>递归子聚类直到可管理的规模</li>
<li>使用小模型生成簇摘要</li>
</ol>
<p><strong>失败原因：</strong> 新闻数据是稀疏的，不是稠密的。HDBSCAN 在数据自然形成簇时有效。新闻文章涵盖多样主题，语义关联弱。</p>
<p>结果：</p>
<ul>
<li>50%以上文章无法聚类</li>
<li>激进参数创建太多微型簇</li>
<li>即使优化，仍有30%以上记录无法分类</li>
</ul>
<p>数据稀疏时，聚类不起作用。</p>
<h2>方法二：大上下文 LLM</h2>
<p>现代 LLM 拥有巨大上下文窗口：</p>
<ul>
<li>Claude Opus 4.5：20万 tokens</li>
<li>Gemini 3 Pro：100万 tokens</li>
</ul>
<p>容纳大数据集的策略：</p>
<ul>
<li><strong>采样</strong>：取10%数据适应上下文</li>
<li><strong>分块</strong>：拆分成多个子数据集，分别处理</li>
</ul>
<p><strong>失败原因：</strong> 幻觉随上下文长度累积。</p>
<p>随着 token 消耗增长，模型对事实的注意力减弱。错误累积：日期偏移、数字漂移、来源混淆、虚构细节出现。</p>
<p>大上下文是必要的，但不充分。需要验证机制。</p>
<h2>方法三：当作代码库文件编辑</h2>
<p>这是关键洞察：<strong>像 Claude Code 这样的编程智能体针对文件操作做了优化。</strong></p>
<p>Claude Code 拥有：</p>
<ul>
<li><code>Read</code> 工具，针对2000行以内的文件优化</li>
<li><code>Edit</code> 工具用于精确修改</li>
<li><code>Write</code> 工具用于文件创建</li>
<li><code>Bash</code> 用于 unix 命令</li>
</ul>
<p>重新定义：把数据集问题转换成代码库问题。</p>
<h3>转换方法</h3>
<ol>
<li><strong>导出为 CSV</strong>：从 Excel/JSON 导出为行式 CSV</li>
<li><strong>预处理</strong>：移除空白，规范化为紧凑格式</li>
<li><strong>分块</strong>：每个文件约200条记录（适配2000行）</li>
<li><strong>当作代码</strong>：操作 CSV 文件 = 操作源代码</li>
</ol>
<p>20万条记录的数据集变成约1000个 CSV 文件。正常代码库规模。Claude Code 自然地处理。</p>
<h3>大规模标注</h3>
</div>

<pre><code class="language-diff">- Column A|Column B|...
+ Tag1,Tag2,Tag3|Column A|Column B|...</code></pre><div class="lang-en">

<p>Claude Code edits each CSV file, adding classification tags to each row. The operation is familiar - just file editing.</p>
<h2>Parallel Task Agents</h2>
<p>Claude Code runs up to 10 Task agents simultaneously. For labeling tasks, assign one agent per CSV chunk:</p>
</div>

<div class="lang-zh">

<p>Claude Code 编辑每个 CSV 文件，为每行添加分类标签。操作很熟悉——就是文件编辑。</p>
<h2>并行 Task 智能体</h2>
<p>Claude Code 可同时运行最多10个 Task 智能体。标注任务中，为每个 CSV 块分配一个智能体：</p>
</div>

<pre><code class="language-text">Running 10 Task agents... (ctrl+o to expand)
   ├─ Tag batch 1 · Processing summary_01.csv...
   ├─ Tag batch 2 · Processing summary_02.csv...
   ├─ Tag batch 3 · Processing summary_03.csv...
   ...
   └─ Tag batch 10 · Processing summary_10.csv...</code></pre><div class="lang-en">

<p>10x parallelism for data processing. The Task tool is Claude Code&#39;s most powerful feature for consulting work.</p>
<h2>The IR Workflow Pattern</h2>
<p>IR = Intermediate Representation. Key architectural pattern for reliable report generation.</p>
</div>

<div class="lang-zh">

<p>数据处理获得10倍并行度。Task 工具是 Claude Code 在咨询工作中最强大的功能。</p>
<h2>IR 工作流模式</h2>
<p>IR = 中间表示。可靠报告生成的关键架构模式。</p>
</div>

<pre><code class="language-text">Raw CSV Data
    ↓ [Labeling, merging, re-ranking, scoring]
PostgreSQL Database (with tags)
    ↓ [Query and filter]
IR (Intermediate Representation - JSON)
    ↓ [Normalization via Task agents]
Normalized IR (deduplicated, translated)
    ↓ [Report generation scripts]
Final Reports (Markdown → XLSX/PDF)</code></pre><div class="lang-en">

<h3>Why IR Matters</h3>
<p>IR provides a checkpoint between data processing and report generation:</p>
<ol>
<li><strong>Auditable</strong>: IR files can be inspected before final output</li>
<li><strong>Iterative</strong>: Regenerate reports without reprocessing data</li>
<li><strong>Verifiable</strong>: Facts in reports trace back to IR</li>
</ol>
<h3>Two-Phase IR Generation</h3>
<p><strong>Phase 1: Raw IR</strong></p>
<ul>
<li>Query database with tag and source filters</li>
<li>Output JSON with candidate articles</li>
</ul>
<p><strong>Phase 2: Normalized IR</strong></p>
<ul>
<li>Task agents merge duplicate topics</li>
<li>Add translations (multilingual support)</li>
<li>Normalize date formats (YYYY-MM-DD)</li>
</ul>
<p>This separation prevents errors from propagating into final reports.</p>
<h2>Report Validation: Preventing Hallucinations</h2>
<p>The critical innovation: <strong>validate every fact in the report has a source reference.</strong></p>
</div>

<div class="lang-zh">

<h3>为什么 IR 重要</h3>
<p>IR 在数据处理和报告生成之间提供检查点：</p>
<ol>
<li><strong>可审计</strong>：最终输出前可检查 IR 文件</li>
<li><strong>可迭代</strong>：无需重新处理数据即可重新生成报告</li>
<li><strong>可验证</strong>：报告中的事实可追溯到 IR</li>
</ol>
<h3>两阶段 IR 生成</h3>
<p><strong>第一阶段：原始 IR</strong></p>
<ul>
<li>使用标签和来源过滤器查询数据库</li>
<li>输出包含候选文章的 JSON</li>
</ul>
<p><strong>第二阶段：规范化 IR</strong></p>
<ul>
<li>Task 智能体合并重复主题</li>
<li>添加翻译（多语言支持）</li>
<li>规范化日期格式（YYYY-MM-DD）</li>
</ul>
<p>这种分离防止错误传播到最终报告。</p>
<h2>报告验证：防止幻觉</h2>
<p>关键创新：<strong>验证报告中的每个事实都有来源引用。</strong></p>
</div>

<pre><code class="language-text">Report Markdown
    ↓ [Extract facts script]
.validation.json (dates, numbers, claims)
    ↓ [Parallel Task agents search sources]
Source references added
    ↓ [Verification script]
Check for NOT_FOUND entries</code></pre><div class="lang-en">

<h3>The report-validator Skill</h3>
<p>A 3-step workflow:</p>
<ol>
<li><strong>Extract Facts</strong>: Script parses markdown, extracts dates/numbers into <code>.validation.json</code></li>
<li><strong>Fill Sources</strong>: Task agents search IR and dataset files in parallel</li>
<li><strong>Check Results</strong>: Script verifies no facts marked <code>&quot;NOT_FOUND&quot;</code></li>
</ol>
<h3>Smart Matching</h3>
<p>The validator handles format variations:</p>
<ul>
<li><strong>Dates</strong>: &quot;2026-01-07&quot;, &quot;2026/01/07&quot;, &quot;January 7&quot;, &quot;1月7日&quot;</li>
<li><strong>Numbers</strong>: &quot;1.8B&quot; = &quot;18亿&quot; = &quot;1.8 billion&quot;</li>
</ul>
<p>Core numeric values must exist in source, even in different formats.</p>
<h3>Zero Tolerance</h3>
<p>If ANY fact lacks a source reference, the report fails validation. This forces:</p>
<ul>
<li>Accurate transcription from sources</li>
<li>No invented details</li>
<li>Traceable claims</li>
</ul>
<h2>Agent Skills: Encapsulating Expertise</h2>
<p>Claude Code skills are reusable instruction sets that encapsulate domain expertise.</p>
</div>

<div class="lang-zh">

<h3>report-validator 技能</h3>
<p>3步工作流：</p>
<ol>
<li><strong>提取事实</strong>：脚本解析 markdown，将日期/数字提取到 <code>.validation.json</code></li>
<li><strong>填充来源</strong>：Task 智能体并行搜索 IR 和数据集文件</li>
<li><strong>检查结果</strong>：脚本验证没有标记为 <code>&quot;NOT_FOUND&quot;</code> 的事实</li>
</ol>
<h3>智能匹配</h3>
<p>验证器处理格式变体：</p>
<ul>
<li><strong>日期</strong>：&quot;2026-01-07&quot;、&quot;2026/01/07&quot;、&quot;January 7&quot;、&quot;1月7日&quot;</li>
<li><strong>数字</strong>：&quot;1.8B&quot; = &quot;18亿&quot; = &quot;1.8 billion&quot;</li>
</ul>
<p>核心数值必须存在于来源中，即使格式不同。</p>
<h3>零容忍</h3>
<p>如果任何事实缺少来源引用，报告验证失败。这强制：</p>
<ul>
<li>从来源准确转录</li>
<li>不添加虚构细节</li>
<li>声明可追溯</li>
</ul>
<h2>Agent 技能：封装专业知识</h2>
<p>Claude Code 技能是封装领域专业知识的可复用指令集。</p>
</div>

<pre><code class="language-text">.claude/skills/
├── generate-report/     # Two-phase IR → Report workflow
├── tag-summaries/       # Multi-tag classification
├── report-validator/    # Fact verification
└── xlsx/                # Excel generation with formulas</code></pre><div class="lang-en">

<h3>Key Skills for Data Analysis</h3>
<table>
<thead>
<tr>
<th>Skill</th>
<th>Purpose</th>
</tr>
</thead>
<tbody><tr>
<td><code>generate-report</code></td>
<td>Orchestrates full pipeline: dedup → IR → normalize → markdown → Excel</td>
</tr>
<tr>
<td><code>tag-summaries</code></td>
<td>Multi-label classification with primary/secondary/social tags</td>
</tr>
<tr>
<td><code>report-validator</code></td>
<td>Extracts facts, searches sources, verifies coverage</td>
</tr>
<tr>
<td><code>xlsx</code></td>
<td>Enterprise Excel with formulas, error checking, styling</td>
</tr>
</tbody></table>
<h2>Key Takeaways</h2>
<ol>
<li><p><strong>Reframe the problem</strong>: Data analysis → codebase file editing. Claude Code is optimized for this.</p>
</li>
<li><p><strong>Chunk strategically</strong>: 200 records per file, 2000 lines max. Fits Claude Code&#39;s tools.</p>
</li>
<li><p><strong>Parallelize with Task agents</strong>: 10x throughput for labeling, classification, validation.</p>
</li>
<li><p><strong>Use IR as checkpoint</strong>: Separate data processing from report generation. Enables iteration and auditing.</p>
</li>
<li><p><strong>Validate everything</strong>: The report-validator pattern catches hallucinations before delivery.</p>
</li>
<li><p><strong>Encapsulate in skills</strong>: Domain expertise becomes reusable, maintainable instruction sets.</p>
</li>
</ol>
<p>The result: enterprise-quality reports from 25K+ articles, with every fact traceable to source data.</p>
<p>Claude Code isn&#39;t just for writing code. It&#39;s a general-purpose agent for any task that can be expressed as file operations. Data analysis fits perfectly.</p>
</div>

<div class="lang-zh">

<h3>数据分析的关键技能</h3>
<table>
<thead>
<tr>
<th>技能</th>
<th>用途</th>
</tr>
</thead>
<tbody><tr>
<td><code>generate-report</code></td>
<td>编排完整流程：去重 → IR → 规范化 → markdown → Excel</td>
</tr>
<tr>
<td><code>tag-summaries</code></td>
<td>带主/次/社媒标签的多标签分类</td>
</tr>
<tr>
<td><code>report-validator</code></td>
<td>提取事实、搜索来源、验证覆盖</td>
</tr>
<tr>
<td><code>xlsx</code></td>
<td>企业级 Excel，带公式、错误检查、样式</td>
</tr>
</tbody></table>
<h2>关键要点</h2>
<ol>
<li><p><strong>重新定义问题</strong>：数据分析 → 代码库文件编辑。Claude Code 针对此做了优化。</p>
</li>
<li><p><strong>策略性分块</strong>：每文件200条记录，最多2000行。适配 Claude Code 的工具。</p>
</li>
<li><p><strong>用 Task 智能体并行化</strong>：标注、分类、验证获得10倍吞吐量。</p>
</li>
<li><p><strong>使用 IR 作为检查点</strong>：分离数据处理和报告生成。支持迭代和审计。</p>
</li>
<li><p><strong>验证一切</strong>：report-validator 模式在交付前捕获幻觉。</p>
</li>
<li><p><strong>封装为技能</strong>：领域专业知识变成可复用、可维护的指令集。</p>
</li>
</ol>
<p>结果：从2.5万多篇文章生成企业级报告，每个事实都可追溯到源数据。</p>
<p>Claude Code 不只是写代码。它是通用智能体，适用于任何可以表达为文件操作的任务。数据分析完美契合。</p>
</div>

      </div>
    </article>

    <footer class="site-footer">
      <p>&copy; 2026 Shiqi Mei</p>
    </footer>
  </div>
  <script type="module" src="../js/highlight.js"></script>
  <script src="../js/lang-toggle.js"></script>
</body>
</html>
