<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Claude Code's Fork and Agent Arguments: Running Skills in Sub-Agents - Shiqi Mei</title>
  <link rel="icon" type="image/png" href="../avatar.png">
  <link rel="stylesheet" href="../css/style.css">
</head>
<body>
  <div class="container">
    <a href="/" class="back-link">&larr; back</a>

    <article>
      <header class="post-header">
        <div class="post-header-row">
          <h1 class="post-title">Claude Code's Fork and Agent Arguments: Running Skills in Sub-Agents</h1>
          <div class="lang-toggle" id="langToggle">
            <button data-lang="en" class="active">EN</button>
            <button data-lang="zh">CN</button>
          </div>
        </div>
        <p class="post-meta">Jan 11, 2026</p>
      </header>

      <div class="post-content">
        <p>In a <a href="/posts/agent-skill-vs-mcp-context-efficiency.html">previous post</a>, I discussed how Agent Skills achieve context efficiency through progressive disclosure and script execution. But I noted a limitation: no nested skill support. Complex workflows couldn&#39;t delegate to sub-skills without polluting the main context.</p>
<p>Claude Code now addresses this with two new skill arguments: <code>context: fork</code> and <code>agent: &lt;type&gt;</code>.</p>
<h2>The Problem: Skill Execution Pollutes Context</h2>
<p>When a skill runs, all its intermediate work happens in the main conversation context:</p>
<ul>
<li>Every <code>Read</code> tool call and its output</li>
<li>Every <code>Grep</code> search result</li>
<li>Every <code>Bash</code> command output</li>
<li>All the reasoning between steps</li>
</ul>
<p>A skill that explores a codebase to answer a question might make 20+ tool calls. Each one consumes tokens. By the time the skill returns its answer, you&#39;ve burned through context that could have been used for actual work.</p>
<p>Script execution helps for deterministic operations. But what about skills that require LLM reasoning throughout - exploring code, making decisions, adapting to what they find?</p>
<h2>The Solution: Fork the Context</h2>
<p>The <code>context: fork</code> argument runs a skill in an isolated sub-agent:</p>
<pre><code class="language-yaml">---
name: analyze-codebase
description: Analyze codebase architecture and patterns
context: fork
---</code></pre><p>When this skill triggers:</p>
<ol>
<li>Claude spawns a sub-agent with fresh context</li>
<li>The sub-agent receives only the skill instructions and user query</li>
<li>The sub-agent executes independently - reads files, searches code, reasons</li>
<li>Only the final result returns to the main conversation</li>
</ol>
<p>All intermediate tool calls, file contents, and reasoning stay in the sub-agent&#39;s context. The main conversation sees just the answer.</p>
<h2>Choosing the Right Agent Type</h2>
<p>The <code>agent: &lt;type&gt;</code> argument specifies which specialized agent runs the skill:</p>
<pre><code class="language-yaml">---
name: explore-architecture
description: Map out the codebase structure and dependencies
context: fork
agent: Explore
---</code></pre><p>Available agent types:</p>
<table>
<thead>
<tr>
<th>Agent</th>
<th>Capabilities</th>
<th>Use Case</th>
</tr>
</thead>
<tbody><tr>
<td><code>general-purpose</code></td>
<td>All tools, full reasoning</td>
<td>Complex multi-step tasks</td>
</tr>
<tr>
<td><code>Explore</code></td>
<td>Fast file search, pattern matching</td>
<td>Codebase exploration</td>
</tr>
<tr>
<td><code>Plan</code></td>
<td>Architecture analysis, step planning</td>
<td>Implementation planning</td>
</tr>
<tr>
<td><code>Bash</code></td>
<td>Command execution only</td>
<td>Shell-heavy operations</td>
</tr>
</tbody></table>
<p>Match the agent type to what the skill needs. An exploration skill benefits from the <code>Explore</code> agent&#39;s optimized search. A deployment skill might use <code>Bash</code> for focused command execution.</p>
<h2>Practical Example</h2>
<p>Consider a skill that answers architecture questions:</p>
<p><strong>Without fork:</strong></p>
<pre><code class="language-text">User: &quot;How does authentication work in this codebase?&quot;

[Skill triggers]
[Read auth/middleware.ts - 200 lines in context]
[Grep for &quot;jwt&quot; - 15 matches in context]
[Read auth/providers/oauth.ts - 150 lines in context]
[Read auth/session.ts - 100 lines in context]
[Reasoning about the auth flow...]

Answer: &quot;Authentication uses JWT tokens with OAuth providers...&quot;</code></pre><p>Total context consumed: ~500+ lines of code, search results, reasoning.</p>
<p><strong>With fork:</strong></p>
<pre><code class="language-text">User: &quot;How does authentication work in this codebase?&quot;

[Skill triggers with context: fork]
[Sub-agent spawns, explores independently]

Answer: &quot;Authentication uses JWT tokens with OAuth providers...&quot;</code></pre><p>Total context consumed in main conversation: just the answer.</p>
<p>The sub-agent did the same work, but in isolation. The main conversation stays clean.</p>
<h2>When to Use Fork</h2>
<p>Use <code>context: fork</code> when your skill:</p>
<ul>
<li>Reads multiple files to synthesize an answer</li>
<li>Performs exploratory searches with uncertain outcomes</li>
<li>Requires multi-step reasoning that generates intermediate artifacts</li>
<li>Could consume significant context if run inline</li>
</ul>
<p>Don&#39;t use fork when:</p>
<ul>
<li>The skill is simple (single file read, one command)</li>
<li>You need the skill&#39;s intermediate results in the main conversation</li>
<li>The overhead of spawning a sub-agent exceeds the context savings</li>
</ul>
<h2>The Complete Picture</h2>
<p>This completes the skill efficiency story:</p>
<ol>
<li><strong>Progressive disclosure</strong>: Only frontmatter loads at startup (~20 tokens per skill)</li>
<li><strong>On-demand loading</strong>: Full skill content loads only when triggered</li>
<li><strong>Script execution</strong>: Deterministic operations run outside context</li>
<li><strong>Context fork</strong>: LLM-driven operations run in isolated sub-agents</li>
</ol>
<p>Each layer reduces context consumption. Together, they make skills dramatically more efficient than traditional tool architectures.</p>
<h2>Configuration</h2>
<p>Add these arguments to your skill&#39;s frontmatter:</p>
<pre><code class="language-yaml">---
name: my-skill
description: What this skill does
context: fork          # Run in isolated sub-agent
agent: Explore         # Use the Explore agent type
---</code></pre><p>Both arguments are optional. Use them together or separately based on your skill&#39;s needs.</p>
<h2>Conclusion</h2>
<p>The <code>context: fork</code> and <code>agent: &lt;type&gt;</code> arguments solve the nested skill problem. Complex skills can now run sophisticated, multi-step operations without consuming main conversation context.</p>
<p>The pattern is simple: isolate expensive operations, return only results. Context is the bottleneck - these tools help you respect it.</p>

      </div>
    </article>

    <footer class="site-footer">
      <p>&copy; 2026 Shiqi Mei</p>
    </footer>
  </div>
  <script type="module" src="../js/highlight.js"></script>
  <script src="../js/lang-toggle.js"></script>
</body>
</html>
